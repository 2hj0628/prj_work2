{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560025e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from datetime import date,datetime,timedelta\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "\n",
    "import requests\n",
    "import sqlite3 as sql\n",
    "import pymysql\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b0e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "<KOBIS 일별 박스오피스 크롤링을 시작합니다.>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21704\\2265360381.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "#kobis 데이터 수집 시작\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"<KOBIS 일별 박스오피스 크롤링을 시작합니다.>\")\n",
    "print()\n",
    "\n",
    "# KOBIS (일별 박스오피스) 페이지 접속하기\n",
    "path = \"C:\\\\web_driver\\\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"https://www.kobis.or.kr/kobis/business/stat/boxs/findDailyBoxOfficeList.do\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6caf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['일자', '영화코드', '순위', '영화명', '개봉일', '매출액', '매출액점유율', '매출액증감(전일대비)', '누적매출액', '관객수', '관객수증감(전일대비)', '누적관객수', '스크린수', '상영횟수']\n",
      "[['2022년 07월 20일(수)', '20208446', '1', '외계+인 1부', '2022-07-20', '1,606,975,118', '37.6%', '1,592,398,118(10,924.0%)', '1,682,670,118', '158,157', '157,092(14,750.4%)', '165,584', '1,959', '8,507'], ['2022년 07월 20일(수)', '20205362', '2', '미니언즈2', '2022-07-20', '1,415,051,698', '33.1%', '1,411,205,698(36,692.8%)', '1,431,483,698', '146,908', '146,486(34,712.3%)', '148,220', '1,128', '4,508'], ['2022년 07월 20일(수)', '20194376', '3', '탑건: 매버릭', '2022-06-22', '625,659,153', '14.6%', '-415,562,584(-39.9%)', '64,049,971,850', '61,324', '-38,763(-38.7%)', '5,989,183', '721', '2,222'], ['2022년 07월 20일(수)', '20209654', '4', '헤어질 결심', '2022-06-29', '218,398,688', '5.1%', '-166,343,262(-43.2%)', '13,751,304,908', '21,092', '-16,205(-43.4%)', '1,341,458', '494', '867'], ['2022년 07월 20일(수)', '20224662', '5', '토르: 러브 앤 썬더', '2022-07-06', '165,754,040', '3.9%', '-241,849,660(-59.3%)', '28,179,840,730', '16,401', '-22,426(-57.8%)', '2,591,359', '604', '1,045'], ['2022년 07월 20일(수)', '20225237', '6', '명탐정 코난: 할로윈의 신부', '2022-07-13', '123,552,800', '2.9%', '-126,766,006(-50.6%)', '2,819,228,666', '12,078', '-12,502(-50.9%)', '271,892', '272', '376'], ['2022년 07월 20일(수)', '20225293', '7', '썸머 필름을 타고!', '2022-07-20', '18,143,400', '0.4%', '18,143,400(100.0%)', '33,350,900', '1,929', '1,929(100.0%)', '3,378', '62', '83'], ['2022년 07월 20일(수)', '20212317', '8', '컴온 컴온', '2022-06-30', '9,622,500', '0.2%', '8,345,100(653.3%)', '140,125,700', '1,874', '1,741(1,309.0%)', '14,983', '25', '27'], ['2022년 07월 20일(수)', '20204548', '9', '범죄도시 2', '2022-05-18', '17,012,000', '0.4%', '-45,749,320(-72.9%)', '131,090,089,130', '1,679', '-4,554(-73.1%)', '12,673,342', '120', '151'], ['2022년 07월 20일(수)', '20225175', '10', '엘비스', '2022-07-13', '11,220,700', '0.3%', '-63,120,810(-84.9%)', '744,204,400', '1,062', '-6,135(-85.2%)', '70,081', '45', '48'], ['2022년 07월 20일(수)', '20224791', '11', '그레이 맨', '2022-07-13', '6,832,800', '0.2%', '-20,600,460(-75.1%)', '212,113,860', '810', '-2,358(-74.4%)', '22,088', '41', '62'], ['2022년 07월 20일(수)', '20210542', '12', '로스트 도터', '2022-07-14', '5,716,800', '0.1%', '333,400(6.2%)', '61,331,100', '592', '30(5.3%)', '6,466', '49', '67'], ['2022년 07월 20일(수)', '20225180', '13', '뒤틀린 집', '2022-07-13', '5,373,200', '0.1%', '-23,848,100(-81.6%)', '293,327,000', '578', '-3,073(-84.2%)', '30,785', '37', '41'], ['2022년 07월 20일(수)', '20225186', '14', '더 킬러: 죽어도 되는 아이', '2022-07-13', '5,650,060', '0.1%', '-36,218,740(-86.5%)', '550,360,900', '568', '-3,561(-86.2%)', '53,312', '60', '68'], ['2022년 07월 20일(수)', '20209297', '15', '니얼굴', '2022-06-23', '4,309,500', '0.1%', '3,229,000(298.8%)', '116,291,600', '481', '328(214.4%)', '12,898', '26', '26'], ['2022년 07월 20일(수)', '20225238', '16', '체리마호: 30살까지 동정이면 마법사가 될 수 있대', '2022-07-13', '4,726,000', '0.1%', '-1,690,600(-26.3%)', '91,221,900', '455', '-150(-24.8%)', '8,205', '25', '26'], ['2022년 07월 20일(수)', '20211568', '17', '아치의 노래, 정태춘', '2022-05-18', '3,167,000', '0.1%', '3,089,000(3,960.3%)', '311,430,210', '291', '282(3,133.3%)', '32,626', '3', '3'], ['2022년 07월 20일(수)', '19978805', '18', '큐어', '2022-07-06', '2,708,960', '0.1%', '-2,552,040(-48.5%)', '195,591,860', '279', '-241(-46.3%)', '18,512', '25', '33'], ['2022년 07월 20일(수)', '20225637', '19', '뿌까의 짜장면파티', '2022-07-04', '1,602,000', '0.0%', '-642,000(-28.6%)', '29,937,000', '267', '-107(-28.6%)', '4,964', '9', '9'], ['2022년 07월 20일(수)', '20224713', '20', '멘', '2022-07-13', '1,997,400', '0.0%', '-3,618,000(-64.4%)', '70,650,060', '212', '-349(-62.2%)', '7,077', '24', '31'], ['2022년 07월 20일(수)', '20223278', '21', '극장판 주술회전 0', '2022-02-17', '1,964,500', '0.0%', '36,400(1.9%)', '6,396,362,500', '192', '12(6.7%)', '643,289', '3', '3'], ['2022년 07월 20일(수)', '20206257', '22', '브로커', '2022-06-08', '1,042,000', '0.0%', '-2,423,700(-69.9%)', '12,571,466,230', '174', '-379(-68.5%)', '1,259,194', '11', '11'], ['2022년 07월 20일(수)', '20224757', '23', '룸 쉐어링', '2022-06-22', '1,548,000', '0.0%', '63,000(4.2%)', '131,250,480', '172', '7(4.2%)', '15,651', '2', '2'], ['2022년 07월 20일(수)', '20216366', '24', '바이킹: 블러드 워', '2021-04-05', '850,000', '0.0%', '850,000(100.0%)', '4,146,000', '170', '170(100.0%)', '830', '1', '1'], ['2022년 07월 20일(수)', '20225977', '25', '베르히만 아일랜드', '2022-08-04', '1,136,000', '0.0%', '1,136,000(100.0%)', '1,739,500', '142', '142(100.0%)', '203', '1', '1'], ['2022년 07월 20일(수)', '20223839', '26', '버즈 라이트이어', '2022-06-15', '774,000', '0.0%', '-1,288,000(-62.5%)', '3,509,077,460', '129', '-186(-59.0%)', '344,343', '1', '1'], ['2022년 07월 20일(수)', '20211686', '27', '임파서블 러브', '2022-07-28', '1,134,000', '0.0%', '1,134,000(100.0%)', '1,732,000', '126', '126(100.0%)', '187', '1', '1'], ['2022년 07월 20일(수)', '20186762', '28', '가을의 낙엽', '', '244,000', '0.0%', '-84,000(-25.6%)', '1,185,000', '122', '-42(-25.6%)', '381', '1', '3'], ['2022년 07월 20일(수)', '20200155', '29', '모어', '2022-06-23', '1,026,000', '0.0%', '-944,000(-47.9%)', '86,584,900', '108', '-70(-39.3%)', '10,173', '14', '14'], ['2022년 07월 20일(수)', '20206061', '30', '쥬라기 월드: 도미니언', '2022-06-01', '1,498,000', '0.0%', '1,447,000(2,837.3%)', '29,233,497,310', '107', '102(2,040.0%)', '2,836,696', '1', '1'], ['2022년 07월 20일(수)', '20216301', '31', '300: 전사의 귀환', '2021-03-22', '500,000', '0.0%', '90,000(22.0%)', '3,291,000', '100', '18(22.0%)', '659', '1', '1'], ['2022년 07월 20일(수)', '20183772', '31', '태일이', '2021-12-01', '1,200,000', '0.0%', '1,200,000(100.0%)', '977,699,590', '100', '100(100.0%)', '118,233', '1', '1'], ['2022년 07월 20일(수)', '20225183', '33', '프리! 더 파이널 스트로크 후편', '2022-06-30', '894,700', '0.0%', '-500,800(-35.9%)', '119,134,860', '92', '-40(-30.3%)', '11,506', '13', '13'], ['2022년 07월 20일(수)', '19940315', '34', '펄프 픽션 ', '1994-09-10', '1,025,200', '0.0%', '816,500(391.2%)', '83,809,300', '81', '64(376.5%)', '8,544', '2', '2'], ['2022년 07월 20일(수)', '20101278', '35', '그을린 사랑', '2011-07-21', '79,000', '0.0%', '8,000(11.3%)', '544,614,800', '79', '8(11.3%)', '69,621', '1', '1'], ['2022년 07월 20일(수)', '20080477', '36', '카라멜', '2008-09-04', '70,000', '0.0%', '70,000(100.0%)', '17,402,000', '70', '70(100.0%)', '2,511', '1', '1'], ['2022년 07월 20일(수)', '20224882', '37', '마녀(魔女) Part2. The Other One', '2022-06-15', '646,800', '0.0%', '-13,734,900(-95.5%)', '28,895,788,270', '68', '-1,404(-95.4%)', '2,802,501', '7', '10'], ['2022년 07월 20일(수)', '19588005', '38', '남태평양', '1971-08-07', '162,500', '0.0%', '162,500(100.0%)', '21,025,424', '65', '65(100.0%)', '11,834', '1', '2'], ['2022년 07월 20일(수)', '20216687', '39', '워 히어로: 솔져 오브 갓', '2021-04-19', '315,000', '0.0%', '315,000(100.0%)', '2,876,000', '63', '63(100.0%)', '576', '1', '1'], ['2022년 07월 20일(수)', '19730023', '39', '흑권', '1973-09-09', '126,000', '0.0%', '-34,000(-21.3%)', '2,422,000', '63', '-17(-21.3%)', '1,211', '1', '3'], ['2022년 07월 20일(수)', '20178501', '41', '니 부모 얼굴이 보고 싶다', '2022-04-27', '290,000', '0.0%', '290,000(100.0%)', '3,948,631,280', '58', '58(100.0%)', '416,375', '1', '1'], ['2022년 07월 20일(수)', '20148170', '42', '나폴레옹과 데지레', '', '114,000', '0.0%', '114,000(100.0%)', '8,689,000', '57', '57(100.0%)', '4,329', '1', '3'], ['2022년 07월 20일(수)', '20210962', '43', '우연과 상상', '2022-05-04', '598,000', '0.0%', '515,400(624.0%)', '257,185,440', '54', '43(390.9%)', '26,077', '4', '4'], ['2022년 07월 20일(수)', '20224648', '44', '배드 럭 뱅잉', '2022-07-28', '599,700', '0.0%', '-457,500(-43.3%)', '9,511,700', '53', '-43(-44.8%)', '847', '1', '1'], ['2022년 07월 20일(수)', '20218189', '45', '군다', '2022-07-14', '394,500', '0.0%', '-11,500(-2.8%)', '5,604,300', '46', '1(2.2%)', '644', '12', '15'], ['2022년 07월 20일(수)', '20134776', '45', '레베카 ', '', '459,000', '0.0%', '399,000(665.0%)', '46,834,500', '46', '40(666.7%)', '6,581', '6', '6'], ['2022년 07월 20일(수)', '20211872', '47', '감동주의보', '2022-06-22', '210,000', '0.0%', '10,000(5.0%)', '19,261,000', '42', '2(5.0%)', '2,145', '3', '3'], ['2022년 07월 20일(수)', '20147108', '48', '호수의 이방인', '', '449,000', '0.0%', '303,000(207.5%)', '39,556,700', '41', '29(241.7%)', '4,886', '7', '7'], ['2022년 07월 20일(수)', '20225479', '49', '핸썸', '2022-07-13', '200,000', '0.0%', '-1,477,100(-88.1%)', '10,243,500', '40', '-143(-78.1%)', '1,143', '2', '2'], ['2022년 07월 20일(수)', '20224767', '50', '메모리', '2022-07-14', '340,000', '0.0%', '-1,053,900(-75.6%)', '13,388,600', '39', '-110(-73.8%)', '1,446', '10', '11'], ['2022년 07월 20일(수)', '20135691', '51', '스펠바운드', '', '37,000', '0.0%', '37,000(100.0%)', '2,248,000', '37', '37(100.0%)', '1,043', '1', '2'], ['2022년 07월 20일(수)', '20224184', '51', '레드 로켓', '2022-03-12', '433,500', '0.0%', '-56,500(-11.5%)', '17,277,100', '37', '-10(-21.3%)', '1,705', '7', '7'], ['2022년 07월 20일(수)', '20224468', '53', '애프터 양', '2022-06-01', '295,000', '0.0%', '-590,400(-66.7%)', '371,155,290', '33', '-77(-70.0%)', '38,279', '7', '8'], ['2022년 07월 20일(수)', '20224995', '54', '베르네 부인의 장미정원', '2022-06-09', '208,000', '0.0%', '84,000(67.7%)', '79,332,400', '32', '18(128.6%)', '8,695', '3', '3'], ['2022년 07월 20일(수)', '20211321', '55', '빅샤크4: 바다공룡 대모험', '2022-07-06', '181,500', '0.0%', '-3,374,500(-94.9%)', '528,498,180', '28', '-493(-94.6%)', '59,398', '7', '7'], ['2022년 07월 20일(수)', '20226007', '56', '굿 럭 투 유, 리오 그랜드', '2022-08-11', '283,000', '0.0%', '283,000(100.0%)', '5,394,000', '26', '26(100.0%)', '497', '1', '1'], ['2022년 07월 20일(수)', '20226150', '57', '전장의 A.I.', '', '24,000', '0.0%', '24,000(100.0%)', '24,000', '24', '24(100.0%)', '24', '1', '1'], ['2022년 07월 20일(수)', '20226064', '58', 'EXiS2022 국내경쟁 5', '', '184,000', '0.0%', '184,000(100.0%)', '280,000', '23', '23(100.0%)', '35', '1', '1'], ['2022년 07월 20일(수)', '20211382', '58', '오마주', '2022-05-26', '76,000', '0.0%', '45,000(145.2%)', '100,530,500', '23', '3(15.0%)', '13,281', '3', '6'], ['2022년 07월 20일(수)', '20225781', '60', '워헌트', '2022-07-07', '180,000', '0.0%', '0(0.0%)', '6,840,000', '20', '0(0.0%)', '760', '2', '2'], ['2022년 07월 20일(수)', '20224533', '60', '데이 투 다이', '2022-07-07', '100,000', '0.0%', '100,000(100.0%)', '900,000', '20', '20(100.0%)', '180', '1', '1'], ['2022년 07월 20일(수)', '20122223', '62', '홀리 모터스', '2013-04-04', '170,000', '0.0%', '170,000(100.0%)', '173,069,800', '18', '18(100.0%)', '21,927', '2', '2'], ['2022년 07월 20일(수)', '20226110', '63', 'EXiS2022 아시아 포럼 3 비디오 히로바', '', '136,000', '0.0%', '136,000(100.0%)', '136,000', '17', '17(100.0%)', '17', '1', '1'], ['2022년 07월 20일(수)', '20226104', '63', 'EXiS2022 회고전 2 레나테 사미', '', '136,000', '0.0%', '136,000(100.0%)', '136,000', '17', '17(100.0%)', '17', '1', '1'], ['2022년 07월 20일(수)', '20167301', '65', '아가씨(확장판)', '', '152,500', '0.0%', '8,500(5.9%)', '165,147,550', '15', '3(25.0%)', '20,268', '1', '1'], ['2022년 07월 20일(수)', '20129037', '66', '백조', '', '13,000', '0.0%', '-1,000(-7.1%)', '7,159,000', '13', '-1(-7.1%)', '3,328', '1', '1'], ['2022년 07월 20일(수)', '20225544', '67', '디어헌터(감독판)', '2022-06-23', '103,000', '0.0%', '-14,800(-12.6%)', '9,975,560', '12', '-3(-20.0%)', '1,029', '2', '2'], ['2022년 07월 20일(수)', '20225820', '67', '러브: 무삭제판', '', '132,000', '0.0%', '132,000(100.0%)', '9,289,700', '12', '12(100.0%)', '841', '1', '1'], ['2022년 07월 20일(수)', '19920097', '69', '녹색광선', '', '66,000', '0.0%', '66,000(100.0%)', '36,045,000', '11', '11(100.0%)', '4,495', '1', '1'], ['2022년 07월 20일(수)', '20215048', '69', '스파이형 모델', '2022-07-20', '76,000', '0.0%', '76,000(100.0%)', '76,000', '11', '11(100.0%)', '11', '4', '6'], ['2022년 07월 20일(수)', '20226108', '71', '그리고 피라미드들', '', '80,000', '0.0%', '80,000(100.0%)', '80,000', '10', '10(100.0%)', '10', '1', '1'], ['2022년 07월 20일(수)', '20224634', '72', '그대가 조국', '2022-05-25', '73,000', '0.0%', '-45,000(-38.1%)', '3,103,219,870', '9', '-7(-43.8%)', '332,857', '2', '2'], ['2022년 07월 20일(수)', '20212392', '73', '경아의 딸', '2022-06-16', '70,000', '0.0%', '-118,000(-62.8%)', '54,240,600', '8', '-16(-66.7%)', '7,989', '3', '3'], ['2022년 07월 20일(수)', '20225002', '74', '위대한 침묵', '2022-06-29', '70,000', '0.0%', '52,000(288.9%)', '80,678,670', '7', '5(250.0%)', '8,588', '1', '1'], ['2022년 07월 20일(수)', '20225252', '75', '우스운게 딱! 좋아!', '2022-06-23', '43,000', '0.0%', '8,000(22.9%)', '8,179,700', '6', '2(50.0%)', '949', '3', '3'], ['2022년 07월 20일(수)', '20224476', '75', '윤시내가 사라졌다', '2022-06-08', '39,000', '0.0%', '15,000(62.5%)', '36,936,200', '6', '3(100.0%)', '4,024', '3', '3'], ['2022년 07월 20일(수)', '20050211', '75', '성냥공장 소녀', '2001-04-28', '39,000', '0.0%', '39,000(100.0%)', '3,363,000', '6', '6(100.0%)', '490', '1', '1'], ['2022년 07월 20일(수)', '20210843', '78', '실종', '2022-06-15', '25,000', '0.0%', '-79,000(-76.0%)', '104,718,700', '5', '-7(-58.3%)', '11,350', '1', '1'], ['2022년 07월 20일(수)', '20224732', '79', '미친 능력', '2022-06-29', '22,000', '0.0%', '20,000(1,000.0%)', '45,998,710', '4', '2(100.0%)', '4,838', '3', '3'], ['2022년 07월 20일(수)', '20226278', '79', '바람', '', '18,000', '0.0%', '18,000(100.0%)', '18,000', '4', '4(100.0%)', '4', '1', '1'], ['2022년 07월 20일(수)', '20226089', '81', '지금 이대로도 괜찮아(인디스데이)', '', '22,000', '0.0%', '14,000(175.0%)', '80,000', '3', '2(200.0%)', '11', '1', '1'], ['2022년 07월 20일(수)', '20225795', '81', '아이언 크로스: 노르망디 상륙작전', '2022-07-21', '30,000', '0.0%', '30,000(100.0%)', '47,000', '3', '3(100.0%)', '5', '1', '1'], ['2022년 07월 20일(수)', '20225491', '81', '보통의 용기', '2022-06-30', '21,000', '0.0%', '-46,000(-68.7%)', '4,455,600', '3', '-8(-72.7%)', '484', '1', '1'], ['2022년 07월 20일(수)', '20218904', '81', '코다', '2021-08-31', '20,000', '0.0%', '20,000(100.0%)', '682,000,599', '3', '3(100.0%)', '75,099', '2', '2'], ['2022년 07월 20일(수)', '20212855', '85', '닥터 스트레인지: 대혼돈의 멀티버스', '2022-05-04', '26,000', '0.0%', '-12,000(-31.6%)', '62,648,511,370', '2', '-2(-50.0%)', '5,884,569', '1', '1'], ['2022년 07월 20일(수)', '20225047', '85', '데쓰 캘린더', '2022-06-23', '11,000', '0.0%', '0(0.0%)', '2,481,500', '2', '0(0.0%)', '262', '2', '2'], ['2022년 07월 20일(수)', '20224720', '85', '그대라는기억 연숙씨', '2022-06-16', '11,000', '0.0%', '0(0.0%)', '13,142,500', '2', '0(0.0%)', '1,414', '2', '2'], ['2022년 07월 20일(수)', '20176068', '85', '나를 만나는 길', '2022-05-12', '10,000', '0.0%', '10,000(100.0%)', '102,666,800', '2', '2(100.0%)', '11,111', '1', '1'], ['2022년 07월 20일(수)', '20226267', '89', '스와핑 맛 본 여자들', '2022-07-20', '1,000', '0.0%', '1,000(100.0%)', '1,000', '1', '1(100.0%)', '1', '1', '1'], ['2022년 07월 20일(수)', '20226219', '89', '그림자라 불리는 남자들', '2022-07-20', '6,000', '0.0%', '6,000(100.0%)', '6,000', '1', '1(100.0%)', '1', '1', '1'], ['2022년 07월 20일(수)', '20226214', '89', '사랑의 무덤', '2022-07-20', '6,000', '0.0%', '6,000(100.0%)', '6,000', '1', '1(100.0%)', '1', '1', '1'], ['2022년 07월 20일(수)', '20226199', '89', '게이샤의 기억', '2022-07-20', '6,000', '0.0%', '6,000(100.0%)', '6,000', '1', '1(100.0%)', '1', '1', '1'], ['2022년 07월 20일(수)', '20210590', '89', '카시오페아', '2022-06-01', '4,000', '0.0%', '-16,000(-80.0%)', '197,060,300', '1', '-1(-50.0%)', '22,156', '1', '1'], ['2022년 07월 20일(수)', '20225815', '89', '좀!', '', '4,000', '0.0%', '4,000(100.0%)', '32,000', '1', '1(100.0%)', '8', '1', '1'], ['2022년 07월 20일(수)', '20225661', '89', '섹스 앤 퓨리', '2022-07-14', '6,000', '0.0%', '6,000(100.0%)', '164,000', '1', '1(100.0%)', '32', '1', '1'], ['2022년 07월 20일(수)', '20226274', '96', '오, 태양', '', '0', '0.0%', '0(100.0%)', '0', '0', '0(100.0%)', '0', '1', '1']]\n"
     ]
    }
   ],
   "source": [
    "# 날짜 입력 후 조회하기\n",
    "start_date = date(2022, 7, 20)\n",
    "end_date = date(2022, 10, 20)\n",
    "\n",
    "rank_list=[]  #일별 박스오피스\n",
    "movie_info_cont=[]  #영화별 세부정보\n",
    "ungathered_movie_list=[]  #세부정보가 수집되지 않은 영화명\n",
    "\n",
    "#전체 차트 수집하기(rank_list=[])\n",
    "while start_date <= end_date :\n",
    "    try :\n",
    "        # 시작날짜 입력\n",
    "        date_from=driver.find_element(By.XPATH,'//*[@id=\"sSearchFrom\"]')\n",
    "        for i in range(10):\n",
    "            date_from.send_keys(Keys.BACKSPACE) \n",
    "        date_from.send_keys(start_date.strftime(\"%Y-%m-%d\")) \n",
    "\n",
    "        # 종료날짜 입력\n",
    "        date_to=driver.find_element(By.XPATH,'//*[@id=\"sSearchTo\"]')\n",
    "        for j in range(10):\n",
    "            date_to.send_keys(Keys.BACKSPACE)\n",
    "        date_to.send_keys(start_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # 조회 버튼 클릭\n",
    "        search_btn=driver.find_element(By.XPATH,'//*[@id=\"searchForm\"]/div/div[5]/button')\n",
    "        search_btn.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #날짜추가\n",
    "        start_date+=timedelta(days=1)\n",
    "\n",
    "        #더보기 클릭하여 전체 자료보기\n",
    "        while True :\n",
    "            try :\n",
    "                driver.find_element(By.LINK_TEXT,\"더보기\").click()\n",
    "            except :\n",
    "                break\n",
    "        \n",
    "        # 페이지 읽어오기       \n",
    "        full_html=driver.page_source\n",
    "        soup=BeautifulSoup(full_html, 'html.parser')\n",
    "\n",
    "        # 검색날짜 \n",
    "        search_date=soup.find('div','board_tit').get_text().replace(\"\\n\",\"\")\n",
    "\n",
    "        # 검색건수\n",
    "        search_total=soup.find('em','fwb').get_text()\n",
    "        print(search_total)\n",
    "        \n",
    "        #영화코드 추출하기\n",
    "        movie_a=soup.find('tbody').find_all('a')\n",
    "        movie_a_list1=[]\n",
    "        movie_a_list2=[]\n",
    "        movie_code_list=[]\n",
    "        for onclick in movie_a :\n",
    "            movie_a_list1.append(onclick['onclick'])\n",
    "        for c in movie_a_list1 :\n",
    "            movie_a_list2.append(c.replace('(',',').replace(')',',').replace(';','').replace(\"'\",\"\").split(','))\n",
    "                    #영화코드\n",
    "        for code in range(len(movie_a_list2)) :\n",
    "            movie_code_list.append(movie_a_list2[code][2])\n",
    "            \n",
    "        # 컬럼 리스트 생성\n",
    "        content_column=soup.find('thead').find_all('th',{'scope':'col'})\n",
    "        column_list=[]\n",
    "        column_list.append('일자')\n",
    "        column_list.append('영화코드')\n",
    "        for column in content_column :\n",
    "            column_list.append(column.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\").replace(\"오름차순내림차순\",\"\"))\n",
    "        print(column_list)\n",
    "\n",
    "        # 항목 리스트 생성\n",
    "        rank_table=soup.find('tbody').find_all('tr')\n",
    "        \n",
    "        num=0\n",
    "        #리스트에 항목 담기\n",
    "        for movie in rank_table :\n",
    "            chart=[]\n",
    "            chart.append(search_date)  #검색일자\n",
    "            chart.append(movie_code_list[num])  #영화코드\n",
    "\n",
    "            #영화 순위\n",
    "            movie_rank=movie.find('td').text.replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            chart.append(movie_rank)\n",
    "\n",
    "            #영화제목\n",
    "            movie_title=movie.find('span','ellip per90').get_text()\n",
    "            chart.append(movie_title)\n",
    "\n",
    "            #개봉일\n",
    "            movie_chart=movie.select('td:nth-child(3)')\n",
    "            for date in movie_chart :\n",
    "                chart.append(date.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\"))\n",
    "\n",
    "            #'매출액', '매출액점유율', '매출액증감(전일대비)', '누적매출액', '관객수' 등\n",
    "            movie_chart=movie.find_all('td','tar')\n",
    "            for record in movie_chart :\n",
    "                chart.append(record.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n",
    "\n",
    "            rank_list.append(chart)\n",
    "            num+=1\n",
    "            \n",
    "        print(rank_list)\n",
    "        \n",
    "# 영화별 세부정보 수집하기 (movie_info_cont=[])\n",
    "        movie_name_list=soup.find_all('span','ellip per90')\n",
    "\n",
    "        for k in movie_name_list :\n",
    "            #영화제목\n",
    "            name=k.get_text()\n",
    "            try :          \n",
    "                # 영화 정보 팝업 띄우기\n",
    "                movie_info=[]\n",
    "                \n",
    "                if all(name not in movie_info for movie_info in movie_info_cont):\n",
    "                    movie_btn=driver.find_element(By.LINK_TEXT,name.strip())\n",
    "                    movie_btn.click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    #영화 정보 가져오기\n",
    "                    movie_html=driver.page_source\n",
    "                    soup=BeautifulSoup(movie_html, 'html.parser')\n",
    "\n",
    "                    #영화제목\n",
    "                    movie_name=soup.find('div','hd_layer').find('strong').get_text()\n",
    "                    movie_info.append(movie_name)\n",
    "\n",
    "                    #영화세부정보contents\n",
    "                    movie_contents=soup.find('dl',class_='ovf cont').find_all('dd')\n",
    "                    for cont in movie_contents :\n",
    "                        movie_info.append(cont.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\").strip())\n",
    "\n",
    "                    #감독, 배우 정보 수집\n",
    "                    try : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        director=soup.find('div','staffMore').find('dd').text.strip()\n",
    "                        movie_staff_dict['감독'].append(director)\n",
    "                        actor_list=soup.find('div','staffMore').find('td').find_all('a')\n",
    "                        for actor in actor_list :\n",
    "                            movie_staff_dict['배우'].append(actor.text.strip())\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "\n",
    "                    except : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "                    \n",
    "                    #영화제목,세부정보,감독,배우 movie_info_cont 리스트에 담기\n",
    "                    movie_info_cont.append(movie_info)\n",
    "#                     print(movie_info_cont)\n",
    "\n",
    "                    # 팝업 창 닫기\n",
    "                    time.sleep(1)\n",
    "                    driver.find_element(By.LINK_TEXT,\"뒤로\").click()\n",
    "                    \n",
    "            except : \n",
    "                print(\"오류 항목을 제외합니다.\")\n",
    "                \n",
    "                # 크롤링이 안된 영화명 수집하기 : 추후 재 검색 실시\n",
    "                ungathered_movie_list.append(name)\n",
    "                continue\n",
    "\n",
    "    except :\n",
    "        print(\"데이터를 수집하지 못하였습니다.\")\n",
    "        break\n",
    "        \n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824333e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(ungathered_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a24b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "['일자', '영화코드', '순위', '영화명', '개봉일', '매출액', '매출액점유율', '매출액증감(전일대비)', '누적매출액', '관객수', '관객수증감(전일대비)', '누적관객수', '스크린수', '상영횟수']\n",
      "데이터를 수집하지 못하였습니다.\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2022, 3, 20)\n",
    "end_date = date(2022, 7, 19)\n",
    "\n",
    "#전체 차트 수집하기(rank_list=[])\n",
    "while start_date <= end_date :\n",
    "    try :\n",
    "        # 시작날짜 입력\n",
    "        date_from=driver.find_element(By.XPATH,'//*[@id=\"sSearchFrom\"]')\n",
    "        for i in range(10):\n",
    "            date_from.send_keys(Keys.BACKSPACE) \n",
    "        date_from.send_keys(start_date.strftime(\"%Y-%m-%d\")) \n",
    "\n",
    "        # 종료날짜 입력\n",
    "        date_to=driver.find_element(By.XPATH,'//*[@id=\"sSearchTo\"]')\n",
    "        for j in range(10):\n",
    "            date_to.send_keys(Keys.BACKSPACE)\n",
    "        date_to.send_keys(start_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # 조회 버튼 클릭\n",
    "        search_btn=driver.find_element(By.XPATH,'//*[@id=\"searchForm\"]/div/div[5]/button')\n",
    "        search_btn.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #날짜추가\n",
    "        start_date+=timedelta(days=1)\n",
    "\n",
    "        #더보기 클릭하여 전체 자료보기\n",
    "        while True :\n",
    "            try :\n",
    "                driver.find_element(By.LINK_TEXT,\"더보기\").click()\n",
    "            except :\n",
    "                break\n",
    "        \n",
    "        # 페이지 읽어오기       \n",
    "        full_html=driver.page_source\n",
    "        soup=BeautifulSoup(full_html, 'html.parser')\n",
    "\n",
    "        # 검색날짜 \n",
    "        search_date=soup.find('div','board_tit').get_text().replace(\"\\n\",\"\")\n",
    "\n",
    "        # 검색건수\n",
    "        search_total=soup.find('em','fwb').get_text()\n",
    "        print(search_total)\n",
    "        \n",
    "        #영화코드 추출하기\n",
    "        movie_a=soup.find('tbody').find_all('a')\n",
    "        movie_a_list1=[]\n",
    "        movie_a_list2=[]\n",
    "        movie_code_list=[]\n",
    "        for onclick in movie_a :\n",
    "            movie_a_list1.append(onclick['onclick'])\n",
    "        for c in movie_a_list1 :\n",
    "            movie_a_list2.append(c.replace('(',',').replace(')',',').replace(';','').replace(\"'\",\"\").split(','))\n",
    "        #영화코드\n",
    "        for code in range(len(movie_a_list2)) :\n",
    "            movie_code_list.append(movie_a_list2[code][2])\n",
    "        print(movie_code_list)\n",
    "            \n",
    "        # 컬럼 리스트 생성\n",
    "        content_column=soup.find('thead').find_all('th',{'scope':'col'})\n",
    "        column_list=[]\n",
    "        column_list.append('일자')\n",
    "        column_list.append('영화코드')\n",
    "        for column in content_column :\n",
    "            column_list.append(column.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\").replace(\"오름차순내림차순\",\"\"))\n",
    "        print(column_list)\n",
    "\n",
    "        # 항목 리스트 생성\n",
    "        rank_table=soup.find('tbody').find_all('tr')\n",
    "        \n",
    "        num=0\n",
    "        #리스트에 항목 담기\n",
    "        for movie in rank_table :\n",
    "            chart=[]\n",
    "            chart.append(search_date)  #검색일자\n",
    "            chart.append(movie_code_list[num])  #영화코드\n",
    "\n",
    "            #영화 순위\n",
    "            movie_rank=movie.find('td').text.replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            chart.append(movie_rank)\n",
    "\n",
    "            #영화제목\n",
    "            movie_title=movie.find('span','ellip per90').get_text()\n",
    "            chart.append(movie_title)\n",
    "\n",
    "            #개봉일\n",
    "            movie_chart=movie.select('td:nth-child(3)')\n",
    "            for date in movie_chart :\n",
    "                chart.append(date.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\"))\n",
    "\n",
    "            #'매출액', '매출액점유율', '매출액증감(전일대비)', '누적매출액', '관객수' 등\n",
    "            movie_chart=movie.find_all('td','tar')\n",
    "            for record in movie_chart :\n",
    "                chart.append(record.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n",
    "\n",
    "            rank_list.append(chart)\n",
    "            num+=1\n",
    "            \n",
    "        print(rank_list)\n",
    "        \n",
    "# 영화별 세부정보 수집하기 (movie_info_cont=[])\n",
    "        movie_name_list=soup.find_all('span','ellip per90')\n",
    "\n",
    "        for k in movie_name_list :\n",
    "            #영화제목\n",
    "            name=k.get_text()\n",
    "            try :          \n",
    "                # 영화 정보 팝업 띄우기\n",
    "                movie_info=[]\n",
    "                \n",
    "                if all(name not in movie_info for movie_info in movie_info_cont):\n",
    "                    movie_btn=driver.find_element(By.LINK_TEXT,name.strip())\n",
    "                    movie_btn.click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    #영화 정보 가져오기\n",
    "                    movie_html=driver.page_source\n",
    "                    soup=BeautifulSoup(movie_html, 'html.parser')\n",
    "\n",
    "                    #영화제목\n",
    "                    movie_name=soup.find('div','hd_layer').find('strong').get_text()\n",
    "                    movie_info.append(movie_name)\n",
    "\n",
    "                    #영화세부정보contents\n",
    "                    movie_contents=soup.find('dl',class_='ovf cont').find_all('dd')\n",
    "                    for cont in movie_contents :\n",
    "                        movie_info.append(cont.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\").strip())\n",
    "\n",
    "                    #감독, 배우 정보 수집\n",
    "                    try : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        director=soup.find('div','staffMore').find('dd').text.strip()\n",
    "                        movie_staff_dict['감독'].append(director)\n",
    "                        actor_list=soup.find('div','staffMore').find('td').find_all('a')\n",
    "                        for actor in actor_list :\n",
    "                            movie_staff_dict['배우'].append(actor.text.strip())\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "\n",
    "                    except : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "                    \n",
    "                    #영화제목,세부정보,감독,배우 movie_info_cont 리스트에 담기\n",
    "                    movie_info_cont.append(movie_info)\n",
    "#                     print(movie_info_cont)\n",
    "\n",
    "                    # 팝업 창 닫기\n",
    "                    time.sleep(1)\n",
    "                    driver.find_element(By.LINK_TEXT,\"뒤로\").click()\n",
    "                    \n",
    "            except : \n",
    "                print(\"오류 항목을 제외합니다.\")\n",
    "                \n",
    "                # 크롤링이 안된 영화명 수집하기 : 추후 재 검색 실시\n",
    "                ungathered_movie_list.append(name)\n",
    "                continue\n",
    "\n",
    "    except :\n",
    "        print(\"데이터를 수집하지 못하였습니다.\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ungathered_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd155bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터를 수집하지 못하였습니다.\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2021, 12, 1)\n",
    "end_date = date(2022, 3, 19)\n",
    "\n",
    "#전체 차트 수집하기(rank_list=[])\n",
    "while start_date <= end_date :\n",
    "    try :\n",
    "        # 시작날짜 입력\n",
    "        date_from=driver.find_element(By.XPATH,'//*[@id=\"sSearchFrom\"]')\n",
    "        for i in range(10):\n",
    "            date_from.send_keys(Keys.BACKSPACE) \n",
    "        date_from.send_keys(start_date.strftime(\"%Y-%m-%d\")) \n",
    "\n",
    "        # 종료날짜 입력\n",
    "        date_to=driver.find_element(By.XPATH,'//*[@id=\"sSearchTo\"]')\n",
    "        for j in range(10):\n",
    "            date_to.send_keys(Keys.BACKSPACE)\n",
    "        date_to.send_keys(start_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        # 조회 버튼 클릭\n",
    "        search_btn=driver.find_element(By.XPATH,'//*[@id=\"searchForm\"]/div/div[5]/button')\n",
    "        search_btn.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #날짜추가\n",
    "        start_date+=timedelta(days=1)\n",
    "\n",
    "        #더보기 클릭하여 전체 자료보기\n",
    "        while True :\n",
    "            try :\n",
    "                driver.find_element(By.LINK_TEXT,\"더보기\").click()\n",
    "            except :\n",
    "                break\n",
    "        \n",
    "        # 페이지 읽어오기       \n",
    "        full_html=driver.page_source\n",
    "        soup=BeautifulSoup(full_html, 'html.parser')\n",
    "\n",
    "        # 검색날짜 \n",
    "        search_date=soup.find('div','board_tit').get_text().replace(\"\\n\",\"\")\n",
    "\n",
    "        # 검색건수\n",
    "        search_total=soup.find('em','fwb').get_text()\n",
    "        print(search_total)\n",
    "        \n",
    "        #영화코드 추출하기\n",
    "        movie_a=soup.find('tbody').find_all('a')\n",
    "        movie_a_list1=[]\n",
    "        movie_a_list2=[]\n",
    "        movie_code_list=[]\n",
    "        for onclick in movie_a :\n",
    "            movie_a_list1.append(onclick['onclick'])\n",
    "        for c in movie_a_list1 :\n",
    "            movie_a_list2.append(c.replace('(',',').replace(')',',').replace(';','').replace(\"'\",\"\").split(','))\n",
    "                    #영화코드\n",
    "        for code in range(len(movie_a_list2)) :\n",
    "            movie_code_list.append(movie_a_list2[code][2])\n",
    "            \n",
    "        # 컬럼 리스트 생성\n",
    "        content_column=soup.find('thead').find_all('th',{'scope':'col'})\n",
    "        column_list=[]\n",
    "        column_list.append('일자')\n",
    "        column_list.append('영화코드')\n",
    "        for column in content_column :\n",
    "            column_list.append(column.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\").replace(\"오름차순내림차순\",\"\"))\n",
    "        print(column_list)\n",
    "\n",
    "        # 항목 리스트 생성\n",
    "        rank_table=soup.find('tbody').find_all('tr')\n",
    "        \n",
    "        num=0\n",
    "        #리스트에 항목 담기\n",
    "        for movie in rank_table :\n",
    "            chart=[]\n",
    "            chart.append(search_date)  #검색일자\n",
    "            chart.append(movie_code_list[num])  #영화코드\n",
    "\n",
    "            #영화 순위\n",
    "            movie_rank=movie.find('td').text.replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            chart.append(movie_rank)\n",
    "\n",
    "            #영화제목\n",
    "            movie_title=movie.find('span','ellip per90').get_text()\n",
    "            chart.append(movie_title)\n",
    "\n",
    "            #개봉일\n",
    "            movie_chart=movie.select('td:nth-child(3)')\n",
    "            for date in movie_chart :\n",
    "                chart.append(date.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\"))\n",
    "\n",
    "            #'매출액', '매출액점유율', '매출액증감(전일대비)', '누적매출액', '관객수' 등\n",
    "            movie_chart=movie.find_all('td','tar')\n",
    "            for record in movie_chart :\n",
    "                chart.append(record.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n",
    "\n",
    "            rank_list.append(chart)\n",
    "            num+=1\n",
    "            \n",
    "        print(rank_list)\n",
    "        \n",
    "# 영화별 세부정보 수집하기 (movie_info_cont=[])\n",
    "        movie_name_list=soup.find_all('span','ellip per90')\n",
    "\n",
    "        for k in movie_name_list :\n",
    "            #영화제목\n",
    "            name=k.get_text()\n",
    "            try :          \n",
    "                # 영화 정보 팝업 띄우기\n",
    "                movie_info=[]\n",
    "                \n",
    "                if all(name not in movie_info for movie_info in movie_info_cont):\n",
    "                    movie_btn=driver.find_element(By.LINK_TEXT,name.strip())\n",
    "                    movie_btn.click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    #영화 정보 가져오기\n",
    "                    movie_html=driver.page_source\n",
    "                    soup=BeautifulSoup(movie_html, 'html.parser')\n",
    "\n",
    "                    #영화제목\n",
    "                    movie_name=soup.find('div','hd_layer').find('strong').get_text()\n",
    "                    movie_info.append(movie_name)\n",
    "\n",
    "                    #영화세부정보contents\n",
    "                    movie_contents=soup.find('dl',class_='ovf cont').find_all('dd')\n",
    "                    for cont in movie_contents :\n",
    "                        movie_info.append(cont.text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\" \",\"\").strip())\n",
    "\n",
    "                    #감독, 배우 정보 수집\n",
    "                    try : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        director=soup.find('div','staffMore').find('dd').text.strip()\n",
    "                        movie_staff_dict['감독'].append(director)\n",
    "                        actor_list=soup.find('div','staffMore').find('td').find_all('a')\n",
    "                        for actor in actor_list :\n",
    "                            movie_staff_dict['배우'].append(actor.text.strip())\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "\n",
    "                    except : \n",
    "                        movie_staff_dict={'감독' : [],'배우' : []}\n",
    "                        movie_info.append(movie_staff_dict)\n",
    "                    \n",
    "                    #영화제목,세부정보,감독,배우 movie_info_cont 리스트에 담기\n",
    "                    movie_info_cont.append(movie_info)\n",
    "#                     print(movie_info_cont)\n",
    "\n",
    "                    # 팝업 창 닫기\n",
    "                    time.sleep(1)\n",
    "                    driver.find_element(By.LINK_TEXT,\"뒤로\").click()\n",
    "                    \n",
    "            except : \n",
    "                print(\"오류 항목을 제외합니다.\")\n",
    "                \n",
    "                # 크롤링이 안된 영화명 수집하기 : 추후 재 검색 실시\n",
    "                ungathered_movie_list.append(name)\n",
    "                continue\n",
    "\n",
    "    except :\n",
    "        print(\"데이터를 수집하지 못하였습니다.\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4418388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장을 위한 컬럼 별 리스트 생성\n",
    "gid_k=[]\n",
    "gmovie_k=[]\n",
    "gmovie2_k=[]\n",
    "gdate_k=[]\n",
    "gmovie_id1=[]\n",
    "\n",
    "gaudience=[]\n",
    "ggenre=[]\n",
    "gopendate=[]\n",
    "gdirec=[]\n",
    "gactor=[]\n",
    "gmovie_id2=[]\n",
    "\n",
    "gdate1=[]\n",
    "gdate2=[]\n",
    "ggenre1=[]\n",
    "\n",
    "for i in range(len(rank_list)):\n",
    "    gid_k.append(i+1)  #번호\n",
    "    gmovie_k.append(rank_list[i][2])  #영화제목\n",
    "    gmovie_id1.append(rank_list[i][1])  #영화코드\n",
    "    gaudience.append(int(rank_list[i][8].replace(\",\",\"\")))  #관객수\n",
    "    \n",
    "    gdate1.append(rank_list[i][0])\n",
    "    gdate2=re.findall('\\d+',gdate1[i])\n",
    "    gdate_k.append('-'.join(gdate2))  #날짜\n",
    "    \n",
    "    if len(rank_list[i][3])==10:\n",
    "        gopendate.append(rank_list[i][3])  #개봉일\n",
    "    else:\n",
    "        gopendate.append('1111-11-11')  #개봉일 데이터 없을시 1111-11-11로 통일\n",
    "        \n",
    "for i in range(len(movie_info_cont)):\n",
    "    gmovie2_k.append(movie_info_cont[i][0])   #영화세부정보 - 영화제목\n",
    "    gmovie_id2.append(movie_info_cont[i][1])  #코드(식별코드)\n",
    "    ggenre1.append(movie_info_cont[i][4].split('|'))\n",
    "    \n",
    "for i in range(len(ggenre1)):\n",
    "    try :\n",
    "        ggenre.append(ggenre1[i][2])   #장르\n",
    "    except :\n",
    "        ggenre.append(\"Null\")    #인덱스 에러일 경우\n",
    "    \n",
    "for i in range(len(movie_info_cont)) :   #감독, 배우\n",
    "    if len(str(list(movie_info_cont[i][-1]['감독'])).replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\"))>0 :\n",
    "        gdirec.append(str(list(movie_info_cont[i][-1]['감독'])).replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "        gactor.append(str(list(movie_info_cont[i][-1]['배우'])).replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "    else :\n",
    "        gdirec.append(\"Null\")\n",
    "        gactor.append(\"Null\")\n",
    "\n",
    "\n",
    "#csv 파일로 저장하기\n",
    "#영화 일별 박스오피스 csv 파일생성\n",
    "kobis_rank=pd.DataFrame()\n",
    "kobis_rank['번호']=gid_k\n",
    "kobis_rank['날짜']=gdate_k\n",
    "kobis_rank['영화제목']=gmovie_k\n",
    "kobis_rank['코드']=gmovie_id1\n",
    "kobis_rank['관객수']=gaudience\n",
    "kobis_rank['개봉일']=gopendate\n",
    "#파일저장\n",
    "kobis_rank.to_csv('kobis_rank.csv',encoding='utf-8-sig',index=False)\n",
    "\n",
    "#영화 별 정보 csv 파일생성\n",
    "kobis_movie=pd.DataFrame()\n",
    "kobis_movie['영화제목']=gmovie2_k\n",
    "kobis_movie['코드']=gmovie_id2\n",
    "kobis_movie['장르']=ggenre\n",
    "kobis_movie['감독']=gdirec\n",
    "kobis_movie['주연배우']=gactor\n",
    "#파일저장\n",
    "kobis_movie.to_csv('kobis_movie.csv',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed91929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a361db3076b165a7c7f06871133b20be1e58cc2d6d3762b83cd1a89e0870dd36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
